{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d581979a-c3d9-47a5-9ec4-dd4a0d1f9240",
   "metadata": {
    "id": "bbc4bdcc"
   },
   "source": [
    "# OpenAlex Cited References\n",
    "### STI 2023\n",
    "#### Eric Schares, Iowa State University; [eschares.github.io](eschares.github.io) \n",
    "#### Sandra Mierz; [https://github.com/smierz](https://github.com/smierz) \n",
    "---\n",
    "\n",
    "<div style='background:#e7edf7'>\n",
    "    This notebook will query the OpenAlex API get a set of publications, pull the cited references in the bibliographies, and answer the questions:\n",
    "    <blockquote>\n",
    "        <b><i>How many articles to do our authors cite? When were those articles published? How recent are they?</i></b>\n",
    "    </blockquote>\n",
    "   </div>\n",
    "\n",
    " \n",
    "**Context**\n",
    "\n",
    "We would like to better understand how campus researchers use journal content. Analyzing which years our authors cite and how many papers they cite gives us a better feel for how content is being used. We can use this information as we make journal cancellation and renewal decisions.\n",
    "\n",
    "- **Part 1**. Pull the Data from OpenAlex API\n",
    "- **Part 2**. Plot the Data\n",
    " - **2.1**. Number of references\n",
    " - **2.2**. Years of references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233e559-c774-4e4f-9739-0f6d55f9be33",
   "metadata": {
    "id": "1aa86a40"
   },
   "source": [
    "---\n",
    "# Part 1. Pull the Data\n",
    "#### (Skip to Part 2 if you already have the data saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701bc1d1-b6b5-4030-b309-f6fc8e3a1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79320df-8e1f-4ec4-890f-a0c122768d03",
   "metadata": {
    "id": "cf302cd7"
   },
   "source": [
    "## To modify for your own use, edit the input parameters:\n",
    "- [ROR ID](https://ror.org/search?query=iowa+state) for your own institution \n",
    "- Date range: from_publication_date - to_publication_date\n",
    "- Email address to get into OpenAlex's polite pool for faster response times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0404fd-c596-42ee-bb31-92a9ec8133fd",
   "metadata": {
    "id": "kFrM3hAwcXj_"
   },
   "outputs": [],
   "source": [
    "# input\n",
    "ror_id = \"https://ror.org/04rswrd78\"\n",
    "from_publication_date = \"2021-01-06\"\n",
    "to_publication_date = \"2021-01-06\"\n",
    "email = \"eschares@iastate.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9691836d-6235-4044-8c5e-eb7f40732c62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "272e7492",
    "outputId": "dc62b17e-67f8-4e73-9c00-3c7940038b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete URL:\n",
      "https://api.openalex.org/works?filter=institutions.ror:https://ror.org/04rswrd78,is_paratext:false,type:journal-article,from_publication_date:2021-01-06,to_publication_date:2021-01-06&mailto=eschares@iastate.edu\n"
     ]
    }
   ],
   "source": [
    "def build_url(ror_id, from_pub_date, to_pub_date, email):\n",
    "  # specify endpoint\n",
    "  endpoint = 'works'\n",
    "\n",
    "  # build the 'filter' parameter\n",
    "  filters = (\n",
    "      f'institutions.ror:{ror_id}',\n",
    "      'is_paratext:false',\n",
    "      'type:journal-article', \n",
    "      f'from_publication_date:{from_pub_date}',\n",
    "      f'to_publication_date:{to_pub_date}'\n",
    "  )\n",
    "\n",
    "  # put the URL together\n",
    "  return f'https://api.openalex.org/{endpoint}?filter={\",\".join(filters)}&mailto={email}'\n",
    "\n",
    "\n",
    "filtered_works_url = build_url(ror_id, from_publication_date, to_publication_date, email)\n",
    "print(f'complete URL:\\n{filtered_works_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726febb-856c-489a-ba03-ff693a22aa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc7e75bc-e0f9-4476-9e97-f957934e8fdf",
   "metadata": {
    "id": "1a07cf66"
   },
   "source": [
    "Send the API call and get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bae0264-ed9e-4269-9a88-e26a3383669b",
   "metadata": {
    "id": "1790d33e"
   },
   "outputs": [],
   "source": [
    "api_response = requests.get(filtered_works_url)\n",
    "parsed_response = api_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf701985-721b-41d3-92d4-8b334f1315d3",
   "metadata": {
    "id": "26df016b"
   },
   "source": [
    "How many publication (\"parent\") results?  \n",
    "And how many OpenAlex pages will this take at the given `per_page`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97e846f9-223b-44d3-a01e-bb716c755e6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4e92f18",
    "outputId": "2e003921-5ed6-49f2-9acd-c78de0e92e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result count: 6\n",
      "number of pages needed: 1\n"
     ]
    }
   ],
   "source": [
    "count = parsed_response['meta']['count']\n",
    "print(f\"result count: {count}\")\n",
    "\n",
    "per_page = 200\n",
    "number_of_pages_needed = int(count / per_page) + (count % per_page > 0) # shorter way to calculate math.ceil\n",
    "print(f\"number of pages needed: {number_of_pages_needed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297361b2-0449-4543-a998-77958042c222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85ebf689-5117-45b9-82ea-5140b7cbbf2e",
   "metadata": {
    "id": "c7e438c4"
   },
   "source": [
    "## Main loop - send a request, go through each page, on each page go through each result, and pull out the pieces we want\n",
    "#### ---- Warning! ----\n",
    "\n",
    "This can take quite a bit of time to run depending on the number of records and number of cited references you're asking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24218cd6-376f-4dad-b5ad-948903dfdfb3",
   "metadata": {
    "id": "ca853cf5"
   },
   "source": [
    "If the estimated time is very long (~hours), shorten your time frame in the `build_url` function to run smaller chunks. Save the dfs separately, then reassemble into one combined dataframe using `new_df = pd.concat(df1,df2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41c70c40-6c0b-4e71-aae4-9a161e35f4db",
   "metadata": {
    "id": "41ef3c99"
   },
   "outputs": [],
   "source": [
    "## GET ONLY PUBLICATIONS AND STORE THEIR REFERENCED WORKS \n",
    "def get_publications(works_url):\n",
    "    api_calls_total = 0\n",
    "    session = requests.Session()\n",
    "\n",
    "    # we will store publications and connection pub2ref separately\n",
    "    publications = []\n",
    "    pub2ref = []\n",
    "\n",
    "    # url with a placeholder for cursor\n",
    "    works_url_with_cursor = works_url + '&cursor={}&per_page=200'\n",
    "\n",
    "    # loop through pages\n",
    "    cursor = '*'\n",
    "    while cursor:\n",
    "        # set cursor value and request page from OpenAlex\n",
    "        url = works_url_with_cursor.format(cursor)\n",
    "        #print(url)\n",
    "        page_with_results = session.get(url).json()\n",
    "        api_calls_total += 1\n",
    "\n",
    "        # loop through partial list of results\n",
    "        results = page_with_results['results']\n",
    "        for work in results:\n",
    "            publications.append((\n",
    "              work['id'],  # keep the OpenAlex ID\n",
    "              work['doi'],\n",
    "              work['publication_year'],\n",
    "              work['title'],\n",
    "              work['host_venue']['display_name'],\n",
    "              work['host_venue']['publisher'],\n",
    "              work['host_venue']['issn_l'],\n",
    "              len(work['referenced_works'])\n",
    "              #kicked out concepts for now\n",
    "            ))\n",
    "\n",
    "            for ref in work['referenced_works']:\n",
    "                pub2ref.append((\n",
    "                    work['id'],\n",
    "                    ref\n",
    "                ))\n",
    "\n",
    "        # update cursor to meta.next_cursor\n",
    "        cursor = page_with_results['meta']['next_cursor']\n",
    "      \n",
    "    print(f\"number of api calls for publications: {api_calls_total}\")\n",
    "    return publications, pub2ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b830dd1c-4599-48b1-bf66-189e1d602f0b",
   "metadata": {
    "id": "db30903f"
   },
   "outputs": [],
   "source": [
    "def get_references(pub2ref):\n",
    "    api_calls_total = 0\n",
    "    session = requests.Session()\n",
    "\n",
    "    references = []\n",
    "\n",
    "    # url with a placeholder for cursor\n",
    "    references_url = \"https://api.openalex.org/works?filter=cited_by:{list_of_ids}&mailto=eschares@iastate.edu\"\n",
    "    references_url_with_cursor = references_url + '&cursor={cursor}&per_page=200'\n",
    "\n",
    "    # filter for publications that have at least one reference\n",
    "    pubs_with_refs = list(set(p[0].replace(\"https://openalex.org/\",\"\") for p in pub2ref))\n",
    "\n",
    "    # take chunk of 50 publications\n",
    "    chunk_size = 50\n",
    "    for i in range(0, len(pubs_with_refs), chunk_size):\n",
    "        publications_slice = pubs_with_refs[i:i + chunk_size]\n",
    "        list_of_ids = \"|\".join(publications_slice)\n",
    "\n",
    "        # loop through pages\n",
    "        cursor = '*'\n",
    "        while cursor:\n",
    "            # set cursor value and request page from OpenAlex\n",
    "            url = references_url_with_cursor.format(list_of_ids=list_of_ids, cursor=cursor)\n",
    "            #print(url)\n",
    "            page_with_results = session.get(url).json()\n",
    "            api_calls_total += 1\n",
    "      \n",
    "            # loop through partial list of results\n",
    "            results = page_with_results['results']\n",
    "            for work in results:\n",
    "                references.append((\n",
    "                    work['id'],  # keep the OpenAlex ID\n",
    "                    work['doi'],\n",
    "                    work['publication_year'],\n",
    "                    work['title'],\n",
    "                    work['host_venue']['display_name'],\n",
    "                    work['host_venue']['publisher'],\n",
    "                    work['host_venue']['issn_l'],\n",
    "                    work['cited_by_count']\n",
    "                    #kicked out concepts for now\n",
    "                 ))\n",
    "\n",
    "            # update cursor to meta.next_cursor\n",
    "            cursor = page_with_results['meta']['next_cursor']\n",
    "\n",
    "    print(f\"number of api calls for references: {api_calls_total}\")\n",
    "    return references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b055bc-3a0b-459d-ade2-25fd23aaf5a2",
   "metadata": {
    "id": "94d43bfc"
   },
   "source": [
    "### Let's run the whole thing and time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9409b6cb-f820-4e3f-ad24-afe5489f1815",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e665b17d",
    "outputId": "c7e45c86-43cd-4999-9530-68c77041bd6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at:  2023-02-27 12:17:35.711010\n",
      "number of api calls for publications: 2\n",
      "retrieved 6 publications\n",
      "\n",
      "Retrieved 6 publications and 309 references (some could be duplicates)\n",
      "If all were unique, I estimate this will take 3.68 seconds, or 0.06 minutes\n",
      "\n",
      "number of api calls for references: 3\n",
      "retrieved 309 references\n",
      "\n",
      "Ended at:  2023-02-27 12:17:36.875750\n",
      "Took 0:00:01.164740\n"
     ]
    }
   ],
   "source": [
    "## MAIN \n",
    "#%%time\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(\"Started at: \", start)\n",
    "\n",
    "# get all publications\n",
    "filtered_works_url = build_url(ror_id, from_publication_date, to_publication_date, email)\n",
    "#print(\"URL for publications: \" + filtered_works_url)\n",
    "publications, pub2ref = get_publications(filtered_works_url)\n",
    "\n",
    "# test case had num_cited_references.sum() of 8369, but of those only 8144 were unique. ~3% duplication\n",
    "# took 125 seconds for 8144 references, or pulling 65/second\n",
    "# turn off printing every reference URL and you get 84/second\n",
    "\n",
    "# store publications\n",
    "print(f\"retrieved {len(publications)} publications\")\n",
    "pubs_only = pd.DataFrame(publications, columns =['publication_id',\n",
    "                                                 'publication_doi', \n",
    "                                                 'publication_year',\n",
    "                                                 'publication_title',\n",
    "                                                 'publication_journal',\n",
    "                                                 'publication_publisher',\n",
    "                                                 'publication_journal_issn',\n",
    "                                                 'num_cited_references'\n",
    "                                                 ])\n",
    "\n",
    "# store publications\n",
    "print(f\"\\nRetrieved {len(publications)} publications and {pubs_only['num_cited_references'].sum()} references (some could be duplicates)\")\n",
    "\n",
    "print(f\"If all were unique, I estimate this will take {round(pubs_only['num_cited_references'].sum() / 84, 2)} seconds, or {round((pubs_only['num_cited_references'].sum() / 84) / 60, 2)} minutes\\n\")\n",
    "\n",
    "pubs_only.to_csv('publications.csv', index=False)\n",
    "\n",
    "\n",
    "# store connection pub2ref\n",
    "pub2ref_df = pd.DataFrame(pub2ref, columns=['publication_id', 'reference_id'])\n",
    "\n",
    "# .csv format probably okay here, human readable\n",
    "pub2ref_df.to_csv('pub2ref.csv', index=False)\n",
    "pub2ref_df\n",
    "\n",
    "# get references\n",
    "references = get_references(pub2ref)\n",
    "\n",
    "# store references\n",
    "print(f\"retrieved {len(references)} references\")\n",
    "refs_only = pd.DataFrame(set(references), columns =['reference_id',\n",
    "                                                 'reference_doi', \n",
    "                                                 'reference_year',\n",
    "                                                 'reference_title',\n",
    "                                                 'reference_journal',\n",
    "                                                 'reference_publisher',\n",
    "                                                 'reference_journal_issn',\n",
    "                                                 'reference_citation_count'\n",
    "                                                 ])\n",
    "\n",
    "# using parquet file format since it can be a big file, smaller size but not human readable\n",
    "refs_only.to_parquet('references.parquet')\n",
    "\n",
    "# add .csv to see what's going on\n",
    "refs_only.to_csv('references.csv')\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(\"\\nEnded at: \", end)\n",
    "\n",
    "print(f\"Took {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a1869-506b-4fdb-b474-15960a1daeef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
